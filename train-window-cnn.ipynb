{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN model on sliding windows!\n",
    "\n",
    "0. Data: MAPS\n",
    "1. Pre-processing (on the fly!)\n",
    "    1. Load the audio file\n",
    "    2. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import IPython.display as ipydisplay\n",
    "import functools\n",
    "import librosa\n",
    "import librosa.display as ldisplay\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import scipy.io.wavfile as wav\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalWindowDataset:\n",
    "    def __init__(self, folder_path, sr=None, windows_per_second=32, crop_len_sec=1, feature_extractor=None) -> None:\n",
    "        path_to_data = pathlib.Path(folder_path)\n",
    "        wav_files = list(path_to_data.glob('**/*.wav'))\n",
    "\n",
    "        self.file_list = wav_files\n",
    "        self.sr = sr\n",
    "        self.windows_per_second = windows_per_second  # no. of windows to create per second of the audio\n",
    "        self.crop_len_sec = crop_len_sec  # HOw many seconds of the audio to consider in one sample\n",
    "\n",
    "        self.feature_extractor = feature_extractor or (lambda x: x)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        file_path = self.file_list[ix]\n",
    "\n",
    "        # If the annotation for this file is missing, raise a ValueError!\n",
    "        annot_path = file_path.with_suffix('.txt')\n",
    "        if not annot_path.exists():\n",
    "            raise ValueError\n",
    "        target_onsets = self._load_target_onsets(annot_path)\n",
    "\n",
    "        # Load the audio file\n",
    "        signal, sr_final = librosa.load(file_path, sr=self.sr)\n",
    "\n",
    "        # Choose a random sample of fixed length\n",
    "        signal_sample, onsets_in_sample = self._get_random_signal_crop(\n",
    "            signal=signal, sr=sr_final, onsets=target_onsets, crop_len_sec=self.crop_len_sec\n",
    "        )\n",
    "\n",
    "        sec_per_window = 1. / self.windows_per_second\n",
    "        # frames_per_window = math.floor(sr_final * 1. / self.windows_per_second)\n",
    "        # Split this signal into multiple windows\n",
    "        signal_windows = []\n",
    "        labels = []\n",
    "\n",
    "        for ix in range(self.windows_per_second):\n",
    "            start_s = ix * sec_per_window\n",
    "            end_s = (ix + 1) * sec_per_window\n",
    "            window = signal_sample[int(start_s * sr_final): int(end_s * sr_final)]\n",
    "\n",
    "            # Apply some pre-processing / feature extraction\n",
    "            features = self.feature_extractor(window)\n",
    "            signal_windows.append(features[np.newaxis, ...])\n",
    "\n",
    "            # Get the target label\n",
    "            onsets_in_window = self._get_onsets_in_range(\n",
    "                onsets=onsets_in_sample, relative=False,\n",
    "                start_s=start_s, end_s=end_s,\n",
    "            )\n",
    "            labels.append(len(onsets_in_window) > 0)  # If there is at least one onset in the window, mark 1, else 0.\n",
    "\n",
    "        signal_windows = np.vstack(signal_windows)\n",
    "        assert signal_windows.shape[0] == self.windows_per_second\n",
    "        labels = np.array(labels).astype(np.long)\n",
    "        assert labels.shape[0] == self.windows_per_second\n",
    "\n",
    "        return {\n",
    "            'signal': signal_sample,\n",
    "            'sr': sr_final,\n",
    "            'onsets': onsets_in_window,\n",
    "\n",
    "            'windows': signal_windows,\n",
    "            'labels': labels,\n",
    "#             'file_path': file_path,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_onsets_in_range(onsets, start_s, end_s, relative=True):\n",
    "        onsets_in_range = onsets[np.bitwise_and(start_s <= onsets[:], onsets[:] <= end_s)]\n",
    "        if relative:\n",
    "            onsets_in_range -= start_s\n",
    "        return onsets_in_range\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_random_signal_crop(signal, sr, onsets, crop_len_sec):\n",
    "        start_s = 0  # FIXME\n",
    "        end_s = start_s + crop_len_sec\n",
    "\n",
    "        signal_sample = signal[start_s * sr: end_s * sr]\n",
    "        onsets_in_sample = SignalWindowDataset._get_onsets_in_range(onsets, start_s, end_s, relative=True)\n",
    "\n",
    "        return signal_sample, onsets_in_sample\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_target_onsets(annot_file_path) -> np.ndarray:\n",
    "        df_annot = pd.read_csv(annot_file_path, sep='\\t', )\n",
    "        target_onsets = df_annot.OnsetTime.values\n",
    "\n",
    "        target_onsets = np.unique(target_onsets)\n",
    "        target_onsets = np.round(target_onsets, decimals=2)\n",
    "        return target_onsets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset/dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_features(signal):\n",
    "    stft = librosa.stft(signal, n_fft=2048)\n",
    "    stft_db = np.abs(stft)\n",
    "    return stft_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SignalWindowDataset(\n",
    "    folder_path='/home/anuj/data/ftps.tsi.telecom-paristech.fr/share/maps/ENSTDkCl/MUS/',\n",
    "    feature_extractor=stft_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = windows.transpose((1, 0, 2)).reshape(1025, -1)\n",
    "stft_db = librosa.amplitude_to_db(np.abs(stft))\n",
    "ldisplay.specshow(stft_db, x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bincounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weights = bincounts.get_bin_counts(dataloader, keys=['labels'], n_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self,) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['windows'].transpose(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss / optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_l = Variable(torch.from_numpy(weights['labels'])).to(DEVICE)\n",
    "loss_func = torch.nn.NLLLoss(weight=weights_l, ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
