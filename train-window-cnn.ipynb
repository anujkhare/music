{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CNN model on sliding windows!\n",
    "\n",
    "### TO-DOs\n",
    "* [x] trian/val/test split\n",
    "* [ ] random crop from the signal\n",
    "* [x] tensorboard\n",
    "* [x] weights saving\n",
    "* [ ] Visualization of the results during training\n",
    "* [x] P/R during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import IPython.display as ipydisplay\n",
    "import functools\n",
    "import librosa\n",
    "import librosa.display as ldisplay\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import scipy.io.wavfile as wav\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import dataset, bincounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset/dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset.SignalWindowDataset(folder_path='/home/anuj/data/m/p_cl/train/',)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=1)\n",
    "\n",
    "dataset_val = dataset.SignalWindowDataset(folder_path='/home/anuj/data/m/p_cl/val/',)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=1)\n",
    "\n",
    "print(len(dataloader_train), len(dataloader_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train))\n",
    "print(batch['features'].shape, batch['labels'].shape)\n",
    "print(batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bincounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weights = bincounts.get_bin_counts(dataloader_train, keys=['labels'], n_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size, stride, padding):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(n_in, n_out, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.BatchNorm2d(n_out),\n",
    "            torch.nn.Dropout2d(p=0, inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "        \n",
    "        \n",
    "class SimpleFrameCNN(torch.nn.Module):\n",
    "    def __init__(self, n_feats, n_channels_in=1, n_classes=2,) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extractor = torch.nn.Sequential(\n",
    "            ConvBlock(n_channels_in, 16, kernel_size=9, stride=1, padding=4),\n",
    "            ConvBlock(16, 32, kernel_size=7, stride=1, padding=3),\n",
    "            ConvBlock(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            ConvBlock(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, n_classes, kernel_size=(n_feats, 1), stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.feature_extractor(x)\n",
    "        probs = F.log_softmax(self.classifier(feats), dim=1)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleFrameCNN(n_feats=513).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = batch['features'].to(DEVICE)\n",
    "pred_probs = model(inputs).shape[1:]\n",
    "assert np.all(pred_probs == np.array([2, 1, inputs.shape[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss / optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_l = Variable(torch.from_numpy(weights['labels'].astype(np.float32)))\n",
    "loss_func = torch.nn.NLLLoss(weight=weights_l, ignore_index=-100).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_str = 'docmus-1.01'\n",
    "\n",
    "# logging\n",
    "weights_folder = \"/opt/weights/{}\".format(model_str)\n",
    "log_folder =  '../tensorboard-logs/{}'.format(model_str)\n",
    "writer = SummaryWriter(log_folder) # writing log to tensorboard\n",
    "print('logging to: {}'.format(weights_folder))\n",
    "\n",
    "os.makedirs(weights_folder)  # MEANT TO FAIL IF IT ALREADY EXISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = collections.namedtuple('Results', ['precision', 'recall', 'f1', 'support', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evalaute(batch, model, loss_func, device, visualize=False):\n",
    "    inputs = batch['features'].to(device)\n",
    "    target_labels = batch['labels'].to(device)\n",
    "\n",
    "    # Predict\n",
    "    label_probs = model(inputs)\n",
    "    assert np.all(label_probs.shape[1:] == np.array([2, 1, inputs.shape[-1]]))\n",
    "    pred_labels = torch.argmax(label_probs, dim=1)\n",
    "    \n",
    "    # loss\n",
    "    loss = loss_func(label_probs, target_labels)\n",
    "\n",
    "    if visualize:\n",
    "        pred_labels = pred_labels.data.cpu().numpy()\n",
    "        target_labels = target_labels.data.cpu().numpy()\n",
    "\n",
    "#         print(pred_labels)\n",
    "#         print(target_labels)\n",
    "        \n",
    "        p, r, f, s = precision_recall_fscore_support(target_labels.squeeze(), pred_labels.squeeze())\n",
    "        results = Results(precision=p[1], recall=r[1], f1=f[1], support=s)\n",
    "\n",
    "        return pred_labels, loss, results\n",
    "\n",
    "    return pred_labels, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100000  # Each epoch would only see a sample each from 26 files\n",
    "val_every = 10\n",
    "save_every = 1000\n",
    "n_val = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epoch < n_epochs:\n",
    "    for i_batch, train_batch in tqdm(enumerate(dataloader_train)):\n",
    "        iteration = epoch * train_size + i_batch\n",
    "\n",
    "        # predict\n",
    "        pred_labels, loss = predict_and_evalaute(train_batch, model, loss_func, DEVICE)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('loss.train', loss.data.cpu().numpy(), iteration)\n",
    "\n",
    "        if iteration % val_every == 0:\n",
    "            val_loss_total = 0\n",
    "            average_precision, average_recall = 0, 0\n",
    "            for ix, val_batch in enumerate(dataloader_val):\n",
    "                _, val_loss, results = predict_and_evalaute(val_batch, model, loss_func, DEVICE, visualize=True)\n",
    "                val_loss_total += val_loss.data.cpu().numpy() / n_val\n",
    "                average_precision += results.precision / n_val\n",
    "                average_recall += results.recall / n_val\n",
    "            \n",
    "            writer.add_scalar('loss.val', val_loss_total, iteration)\n",
    "            writer.add_scalar('acc.precision.val', average_precision, iteration)\n",
    "            writer.add_scalar('acc.recall.val', average_recall, iteration)\n",
    "            \n",
    "        if iteration % save_every == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(weights_folder, '{}.pt'.format(iteration)))\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
